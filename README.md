# Web Crawler
Web Crawler - это учебный проект, представляющий поискового паука. Он позволяет сканировать веб-страницы с необходимой 
глубиной, собирать и индексировать слова с каждой страницы. Затем делать запросы и получать ранжированный список сайтов 
в соответствии с частотой упоминания слов из запроса и алгоритмом PageRank.

# Запуск
Для начала нужно установить все необходимые библиотеки:
```
pip install -r requirements.txt
```
